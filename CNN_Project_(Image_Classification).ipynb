{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Project (Image_Classification).ipynb",
      "provenance": [],
      "mount_file_id": "1vz7mI2Qy6zdoSCQfjxDxertHz5rOMKpN",
      "authorship_tag": "ABX9TyNaHwXyE0nt5G8FOYU9diI4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mafiTec/Deep-Neural-Networks/blob/main/CNN_Project_(Image_Classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "UDRjJCfQqkPD",
        "outputId": "a889b2bc-90a3-4d63-f6da-0600be310b09"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='/content/drive/MyDrive/Deep Neural Networks/cn.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xd2OV5uqvR_"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHcsoUHlDF9W"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_dkhHYqtF2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJX225e2C_6f"
      },
      "source": [
        "# Specifying the TensorFlow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lDQ7g5mtq29s",
        "outputId": "82bb837e-561b-4b1d-acb8-cbe809ca8657"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODAyektWC7A2"
      },
      "source": [
        "# Testing for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xxOk1Zs2q3GO",
        "outputId": "c83d3e8b-e681-4f30-c9f1-d5f64dd76fc1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQweCmWwC3xv"
      },
      "source": [
        "# Mounting Google Drive locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onzgWXTYq3JX"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Deep Neural Networks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuxnT22wCsKG"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XpXQOQ1q3Mg",
        "outputId": "c04f6918-4cd6-4842-dc10-2dd3ebb66b9f"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Deep Neural Networks/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7OUU701CoV3"
      },
      "source": [
        "# Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc5QDcS111Xv",
        "outputId": "19716c23-86ac-409b-ba64-e8731bf1df7f"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Deep Neural Networks/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-SA6cvdCaSu"
      },
      "source": [
        "# Building the CNN\n",
        "\n",
        "# Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsWDUE4111gf"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP7DTUf6CXF_"
      },
      "source": [
        "# Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTiye08u11jn"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkgWtj3QCTY_"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33yQ3RxG11n8"
      },
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YF-6CWYCPXQ"
      },
      "source": [
        "# Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saKP5FzN2Fhm"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBIJGfByCL7N"
      },
      "source": [
        "# Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWvop9uu2Flc"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwnzJnQzCIOm"
      },
      "source": [
        "# Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5H3GqBW2Foo"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_DhVldxCEg2"
      },
      "source": [
        "# Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx0Kd3S82FsG"
      },
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjvDkkTyB_h2"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwbXJkv02FuV",
        "outputId": "7d6cabe4-e028-4b7d-cf7b-b9cc2cc9568c"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,217\n",
            "Trainable params: 813,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtYTRdFOB5du"
      },
      "source": [
        "#Training the CNN\n",
        "\n",
        "#Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzkJdXwx2Q5d"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ujos5SgB1T_"
      },
      "source": [
        "# Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hu3Z57P2RFH",
        "outputId": "738d464e-704a-4ce9-ec3f-6186efd34ca6"
      },
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 2001s 16s/step - loss: 0.6866 - accuracy: 0.5570 - val_loss: 0.6803 - val_accuracy: 0.5300\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 31s 251ms/step - loss: 0.6419 - accuracy: 0.6240 - val_loss: 0.6199 - val_accuracy: 0.6520\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 31s 249ms/step - loss: 0.5883 - accuracy: 0.6867 - val_loss: 0.5668 - val_accuracy: 0.7110\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 31s 246ms/step - loss: 0.5454 - accuracy: 0.7197 - val_loss: 0.5960 - val_accuracy: 0.6770\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 31s 248ms/step - loss: 0.5272 - accuracy: 0.7310 - val_loss: 0.5157 - val_accuracy: 0.7470\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 31s 248ms/step - loss: 0.5167 - accuracy: 0.7445 - val_loss: 0.4989 - val_accuracy: 0.7610\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 32s 252ms/step - loss: 0.5052 - accuracy: 0.7508 - val_loss: 0.4988 - val_accuracy: 0.7640\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 31s 247ms/step - loss: 0.4967 - accuracy: 0.7487 - val_loss: 0.4829 - val_accuracy: 0.7650\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 31s 250ms/step - loss: 0.4760 - accuracy: 0.7703 - val_loss: 0.4997 - val_accuracy: 0.7680\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 31s 247ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7670\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 31s 248ms/step - loss: 0.4558 - accuracy: 0.7840 - val_loss: 0.5092 - val_accuracy: 0.7690\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 31s 244ms/step - loss: 0.4466 - accuracy: 0.7872 - val_loss: 0.4749 - val_accuracy: 0.7840\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 30s 241ms/step - loss: 0.4246 - accuracy: 0.8055 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 30s 241ms/step - loss: 0.4161 - accuracy: 0.8138 - val_loss: 0.5023 - val_accuracy: 0.7660\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 30s 242ms/step - loss: 0.4171 - accuracy: 0.7997 - val_loss: 0.4868 - val_accuracy: 0.7830\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 30s 242ms/step - loss: 0.3885 - accuracy: 0.8207 - val_loss: 0.4988 - val_accuracy: 0.7790\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 31s 247ms/step - loss: 0.3766 - accuracy: 0.8273 - val_loss: 0.4911 - val_accuracy: 0.7800\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 31s 246ms/step - loss: 0.3617 - accuracy: 0.8335 - val_loss: 0.5041 - val_accuracy: 0.7790\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 31s 244ms/step - loss: 0.3508 - accuracy: 0.8443 - val_loss: 0.5482 - val_accuracy: 0.7580\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 31s 244ms/step - loss: 0.3404 - accuracy: 0.8447 - val_loss: 0.5059 - val_accuracy: 0.7870\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 31s 244ms/step - loss: 0.3302 - accuracy: 0.8510 - val_loss: 0.5627 - val_accuracy: 0.7660\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 30s 242ms/step - loss: 0.3188 - accuracy: 0.8583 - val_loss: 0.5241 - val_accuracy: 0.7900\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 31s 245ms/step - loss: 0.3083 - accuracy: 0.8660 - val_loss: 0.6087 - val_accuracy: 0.7690\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 31s 245ms/step - loss: 0.3094 - accuracy: 0.8730 - val_loss: 0.5679 - val_accuracy: 0.7790\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 31s 246ms/step - loss: 0.2910 - accuracy: 0.8733 - val_loss: 0.5142 - val_accuracy: 0.7890\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb85cd99810>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flkeXM2j2WKG"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/Deep Neural Networks/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrlVTXVBuh-"
      },
      "source": [
        "# Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-wIeq2E2WOp",
        "outputId": "61f0331a-c798-4368-9bbf-a645f5863e18"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itCwf8Z62WS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}